# -*- coding: utf-8 -*-
"""Jino_Kwon_Thesis_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pwzrd5FdmB4gllRtejne9lQpIMJdL3zx

# Load Data
"""

#Activating Google Drive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

import plotly.graph_objs as go

###Google Drive
import nltk
nltk.download('wordnet')
nltk.download('punkt')

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import numpy as np
import re
from numpy import inf

from nltk.tokenize import word_tokenize
from nltk.collocations import *
from nltk import FreqDist
lemmatizer = nltk.stem.WordNetLemmatizer()
nltk.download('stopwords')
from nltk.corpus import stopwords 
from nltk.stem import PorterStemmer

# Senator raw Tweeter data
df = pd.read_csv("/content/drive/My Drive/Colab Notebooks/thesis/senator_all.csv")
print(df[(df['retweet_count'] == 0)].count)
df.head()

"""# Data Preparation"""

# Drop unnecessary columns
df = df.drop(["rowname", "created_at", "favorite_count", "elite_idx", "dw_extr", "dwextr_rs", "AffectCount", "MoralCount", "neg_uniqueCount",	"pos_uniqueCount", "shared_negCount", "shared_posCount"], axis=1)
df.rename(columns={"elite_new": "senator", "dwscore.y": "dwscore", "genderfx":"gender", "shared":"moral-emo"}, inplace = True)

# Recode categorical values so that '1' means 'yes' and '0' means 'no'
df.url = df.url + 0.5
df.media = df.media + 0.5
df.gender = df.gender + 0.5

df.head()

# Clean and Lemmatize
df1 = df.copy() 

stop_words = set(stopwords.words('english'))

punctuation = '''!"@#$%&'()*+,-./:;<=>?[\]^_`{|}~'''
def clean_lemma(instring, spaces = True): #removes punctuation and double spaces, replacing them w/ single spaces
    instring.replace("\n"," ")
    for x in punctuation:
            instring = instring.replace(x, " ")
    if spaces:
        while instring.find("  ") > -1:
            instring = instring.replace("  ", " ")
    else:
        while instring.find(" ") > -1:
            instring = instring.replace(" ","")
    instring = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(instring)]
    instring = [word for word in instring if word not in stop_words]
    instring = ' '.join(instring)
    return instring

df1['clean_text'] = df1['text'].str.lower()
df1['clean_text'] = df1.clean_text.apply(clean_lemma)
df1.tail()

# add a column for retweetablity
def retweetable(x):
    if x < 6 : return 0
    else : return 1
  
df1["retweetable"] = df1["retweet_count"].apply(retweetable)
print(df1["retweetable"].value_counts())
df1.head()

"""## Sentiment Analysis"""

# Prepping the NRC dictionary for sentiment analysis
filepath = "/content/drive/My Drive/Colab Notebooks/thesis/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt"
nrc_df = pd.read_csv(filepath,  names=["word", "emotion", "association"], sep='\t')

# Filter out entries not associated with any emotion
nrc_df = nrc_df[nrc_df.association != 0]

# Create dictionaries for specific emotions
emotions = {
    'outrage': ['anger', 'disgust'],
    'fear': ['fear'],
    'positive': ['positive'],
    'negative': ['negative']
}

# Word counts for each dictionary
print(nrc_outrage.count)
print(nrc_fear.count)
print(nrc_pos.count)
print(nrc_neg.count)

# Create functions for sentiment scoring
def sentiment_score(txt, emotion):
    token = nltk.word_tokenize(txt)
    word_set = set(token)
    emotion_words = set(nrc_df[nrc_df.emotion.isin(emotions[emotion])]['word'])
    emotion_count = len(word_set.intersection(emotion_words))
    return emotion_count / len(token)

# Create a new column for each sentiment score
for emotion in emotions:
    df1[emotion] = df1.clean_text.apply(lambda x: sentiment_score(x, emotion))

# The number of moral-emotional words needs to be divided by the length of tokens for normalization
df1 = df.copy() 
def token_count(txt):
    token = nltk.word_tokenize(txt)
    return len(token)
df1['token_num'] = df1.clean_text.apply(token_count)
df1['moral-emo'] = df1.apply(lambda x: x['moral-emo']/x['token_num'], axis=1)
# Dropping the 'token_num' column as it is no longer needed
df1 = df1.drop(["token_num"], axis=1)

# Save the df1 file
df1.to_csv('preprocessed_data.csv')
!cp preprocessed_data.csv "/content/drive/My Drive/Colab Notebooks/thesis/"

#  For explatory analysis

# Create a new column for a ln value of 'followers'
df1['ln_followers'] = np.log(df1['followers'])
# Create a new column for a ln value of 'retweet'
df1['ln_retweet'] = np.log(df1['retweet_count'])
# Replaced all '-inf' to 0
df1 = df1.replace({'ln_retweet': {-inf: 0}})

# Save the df1 file
df1.to_csv('preprocessed_data1.csv')
!cp preprocessed_data1.csv "/content/drive/My Drive/Colab Notebooks/thesis/"

"""# Building Prediction Models"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import numpy as np
# Visualization
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import pyplot
from xgboost import plot_importance

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

from sklearn.svm import SVR
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import make_pipeline
import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.metrics import classification_report
from sklearn.metrics import auc
from sklearn.metrics import roc_curve
from sklearn.model_selection import KFold
kfold = KFold(n_splits=5)

# Supress Warningsv
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=DataConversionWarning)

df = pd.read_csv("/content/drive/My Drive/Colab Notebooks/thesis/preprocessed_data.csv")
df.tail()

"""## Description of Data

### Heatmap (Correlation Matrix Visualization)
"""

features = df[['retweetable', 'posneg', 'moral-emo', 'outrage', 'fear', 'followers', 'dwscore', 'url', 'media', 'gender']]

plt.figure(figsize=(10,8))
sns.heatmap(features.corr(method='pearson'), annot=True, fmt='.2g', cbar_kws= {'orientation': 'horizontal'})

plt.show()

"""* how many rows had a zero for each sentiment analysis"""

print("POSITIVE-NEGATIVE SENTIMENT")
print(df[(df['posneg'] == 0)].count)
print("MORAL-EMOTIONAL SENTIMENT")
print(df[(df['moral-emo'] == 0)].count)
print("OUTRAGE AND FEAR SENTIMENT")
print(df[(df['outrage'] == 0) & (df['fear'] == 0)].count)

df.hist(column='retweet_count')

df.hist(column='followers')

df1 = df[['retweet_count', 'retweetable', 'posneg', 'moral-emo', 'fear', 'outrage', 'dwscore', 'url','media', 'gender', 'followers']].copy()
des = df1.describe()
des = des.transpose()
des

"""## ML models with pos/neg"""

# train test split
X = df[['url', 'media', 'followers', 'dwscore', 'gender', 'posneg']]
y = df['retweetable']

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
scaler = StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""* Penalizaed Logistic Regression Model w/ L2 Penalty"""

logreg_pipe1 = make_pipeline(LogisticRegression(penalty='l2'))
logreg_param_grid1 = {'logisticregression__C': np.linspace(1, 100, 100)}
logreg_grid1 = GridSearchCV(logreg_pipe1, logreg_param_grid1, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("LOGISTIC REGRESSION W/ L2 Penalty (SCALED DATA)")
print("Best Parameter: {}".format(logreg_grid1.best_params_))
print("Test set Score: {:.4f}".format(logreg_grid1.score(X_test_scaled, y_test)))

y_pred = np.array(logreg_grid1.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* KNN Classifier"""

knn_pipe1 = make_pipeline(KNeighborsClassifier())
knn_param_grid1 = {'kneighborsclassifier__n_neighbors': range(1, 30)}
knn_grid1 = GridSearchCV(knn_pipe1, knn_param_grid1, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("KNN CLASSIFER (SCALED DATA)")
print("Best Parameter: {}".format(knn_grid1.best_params_))
print("Test set Score: {:.4f}".format(knn_grid1.score(X_test_scaled, y_test)))

y_pred = np.array(knn_grid1.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* Random Forest Classifier"""

rfc_pipe1 = make_pipeline(RandomForestClassifier(random_state=42))
rfc_param_grid1 = {'randomforestclassifier__n_estimators': [100, 500, 1000],
                  'randomforestclassifier__max_depth': [6, 7, 8]}
rfc_grid1 = GridSearchCV(rfc_pipe1, rfc_param_grid1, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("RANDOM FOREST CLASSIFIER")
print("Best Parameter: {}".format(rfc_grid1.best_params_))
print("Test set Score: {:.4f}".format(rfc_grid1.score(X_test_scaled, y_test)))

y_pred = np.array(rfc_grid1.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* XGBoost Model"""

xgb_pipe1 = make_pipeline(xgb.XGBClassifier())
xgb_param_grid1 = {'xgbclassifier__max_depth': [6, 7, 8]}
xgb_grid1 = GridSearchCV(xgb_pipe1, xgb_param_grid1, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("XGBOOST CLASSIFIER")
print("Best Parameter: {}".format(xgb_grid1.best_params_))
print("Test set Score: {:.4f}".format(xgb_grid1.score(X_test_scaled, y_test)))

y_pred = np.array(xgb_grid1.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""### Create a Feature Importance Plot for the Best Model : XGBoost


"""

def plot_feature_importance(importance, names):
  #Create arrays from feature importance and feature names
  feature_importance = np.array(importance)
  feature_names = np.array(names)

  #Create a DataFrame using a Dictionary
  data={'feature_names':feature_names,'feature_importance':feature_importance}
  fi_df = pd.DataFrame(data)

  #Sort the DataFrame in order decreasing feature importance
  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)
  print(fi_df)

  #Define size of bar plot
  plt.figure(figsize=(10,8))
  #Plot Searborn bar chart
  ax = sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'], palette="Blues_r")

  for p in ax.patches:
    ax.annotate("%.4f" % p.get_width(), xy=(p.get_width(), p.get_y()+p.get_height()/2),
            xytext=(5, 0), textcoords='offset points', ha="left", va="center")
  #Add chart labels
  plt.xlabel('FEATURE IMPORTANCE')
  plt.ylabel('FEATURE NAMES')

# A feature importance plot for a XG Boost model
# fitting the model with best parameters
xgb1 = xgb.XGBClassifier(max_depth=7, importance_type='weight')
xgb1.fit(X_train_scaled, y_train)
print(xgb1.feature_importances_)
plot_feature_importance(xgb1.feature_importances_, X.columns)

"""## ML models with moral-emotions"""

# train test split
X = df[['url', 'media', 'followers', 'dwscore', 'gender', 'moral-emo']]
y = df['retweetable']

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
scaler = StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""* Penalizaed Logistic Regression Model w/ L2 penalty"""

logreg_pipe2 = make_pipeline(LogisticRegression(penalty='l2'))
logreg_param_grid2 = {'logisticregression__C': np.linspace(1, 100, 100)}
logreg_grid2 = GridSearchCV(logreg_pipe2, logreg_param_grid2, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("LOGISTIC REGRESSION W/ L2 Penalty (SCALED DATA)")
print("Best Parameter: {}".format(logreg_grid2.best_params_))
print("Test set Score: {:.4f}".format(logreg_grid2.score(X_test_scaled, y_test)))

y_pred = np.array(logreg_grid2.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* KNN Classifier"""

knn_pipe2 = make_pipeline(KNeighborsClassifier())
knn_param_grid2 = {'kneighborsclassifier__n_neighbors': range(1, 30)}
knn_grid2 = GridSearchCV(knn_pipe2, knn_param_grid2, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("KNN CLASSIFER (SCALED DATA)")
print("Best Parameter: {}".format(knn_grid2.best_params_))
print("Test set Score: {:.4f}".format(knn_grid2.score(X_test_scaled, y_test)))

y_pred = np.array(knn_grid2.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* Random Forest Classifier"""

rfc_pipe2 = make_pipeline(RandomForestClassifier(random_state=42))
rfc_param_grid2 = {'randomforestclassifier__n_estimators': [100, 500, 1000],
                  'randomforestclassifier__max_depth': [6, 7, 8]}
rfc_grid2 = GridSearchCV(rfc_pipe2, rfc_param_grid2, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("RANDOM FOREST CLASSIFIER")
print("Best Parameter: {}".format(rfc_grid2.best_params_))
print("Test set Score: {:.4f}".format(rfc_grid2.score(X_test_scaled, y_test)))

y_pred = np.array(rfc_grid2.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* XGBoost Model"""

xgb_pipe2 = make_pipeline(xgb.XGBClassifier())
xgb_param_grid2 = {'xgbclassifier__max_depth': [6, 7, 8]}
xgb_grid2 = GridSearchCV(xgb_pipe2, xgb_param_grid2, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("XGBOOST CLASSIFIER")
print("Best Parameter: {}".format(xgb_grid2.best_params_))
print("Test set Score: {:.4f}".format(xgb_grid2.score(X_test_scaled, y_test)))

y_pred = np.array(xgb_grid2.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""### Create a Feature Importance Plot for the Best Model : XGBoost"""

# A feature importance plot for a XG Boost model
# fitting the model with best parameters
xgb2 = xgb.XGBClassifier(max_depth=7, importance_type='weight')
xgb2.fit(X_train_scaled, y_train)

plot_feature_importance(xgb2.feature_importances_, X.columns)

"""## ML models with outrage and fear"""

# train test split
X = df[['url', 'media', 'followers', 'dwscore', 'gender', 'outrage', 'fear']]
y = df['retweetable']

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
scaler = StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""* Penalizaed Logistic Regression Model w/ L2 penalty"""

logreg_pipe3 = make_pipeline(LogisticRegression(penalty='l2'))
logreg_param_grid3 = {'logisticregression__C': np.linspace(1, 100, 100)}
logreg_grid3 = GridSearchCV(logreg_pipe3, logreg_param_grid3, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("LOGISTIC REGRESSION W/ L2 Penalty (SCALED DATA)")
print("Best Parameter: {}".format(logreg_grid3.best_params_))
print("Test set Score: {:.4f}".format(logreg_grid3.score(X_test_scaled, y_test)))

y_pred = np.array(logreg_grid3.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* KNN Classifier"""

knn_pipe3 = make_pipeline(KNeighborsClassifier())
knn_param_grid3 = {'kneighborsclassifier__n_neighbors': range(1, 30)}
knn_grid3 = GridSearchCV(knn_pipe3, knn_param_grid3, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("KNN CLASSIFER (SCALED DATA)")
print("Best Parameter: {}".format(knn_grid3.best_params_))
print("Test set Score: {:.4f}".format(knn_grid3.score(X_test_scaled, y_test)))

y_pred = np.array(knn_grid3.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* Random Forest Classifier"""

rfc_pipe3 = make_pipeline(RandomForestClassifier(random_state=42))
rfc_param_grid3 = {'randomforestclassifier__n_estimators': [100, 500, 1000],
                  'randomforestclassifier__max_depth': [6, 7, 8]}
rfc_grid3 = GridSearchCV(rfc_pipe3, rfc_param_grid3, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("RANDOM FOREST CLASSIFIER")
print("Best Parameter: {}".format(rfc_grid3.best_params_))
print("Test set Score: {:.4f}".format(rfc_grid3.score(X_test_scaled, y_test)))

y_pred = np.array(rfc_grid3.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""* XGBoost Model"""

xgb_pipe3 = make_pipeline(xgb.XGBClassifier())
xgb_param_grid3 = {'xgbclassifier__max_depth': [6, 7, 8]}
xgb_grid3 = GridSearchCV(xgb_pipe3, xgb_param_grid3, cv=kfold, scoring='roc_auc').fit(X_train_scaled, y_train)

print("XGBOOST CLASSIFIER")
print("Best Parameter: {}".format(xgb_grid3.best_params_))
print("Test set Score: {:.4f}".format(xgb_grid3.score(X_test_scaled, y_test)))

y_pred = np.array(xgb_grid3.predict(X_test_scaled))
print(classification_report(y_test, y_pred))

"""### Create a Feature Importance Plot for the Best Model"""

# A feature importance plot for a XG Boost model
# fitting the model with best parameters
xgb3 = xgb.XGBClassifier(max_depth=7, importance_type='weight')
xgb3.fit(X_train_scaled, y_train)

plot_feature_importance(xgb3.feature_importances_, X.columns)

"""# Visualization of General Performance Comparison"""

# peformance results
pos_neg = [0.6996, 0.8113, 0.8310, 0.8376]
moral_emotion = [0.7071, 0.8183, 0.8285, 0.8343]
outrage_fear = [0.7082, 0.8092, 0.8310, 0.8393]

labels = ['Logistic Regression', 'k-NN Classifier', 'Random Forest', 'XGBoost']
bar_width = 0.3 # set the bar width

x = np.arange(len(labels))

fig, ax = plt.subplots(figsize=(10,8))
r1 = np.arange(len(pos_neg))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]

# make the plot
row1 = ax.bar(r1, pos_neg, color='lightsteelblue', width=bar_width, edgecolor='white', label='pos-neg')
row2 = ax.bar(r2, moral_emotion, color='cornflowerblue', width=bar_width, edgecolor='white', label='moral-emotion')
row3 = ax.bar(r3, outrage_fear, color='midnightblue', width=bar_width, edgecolor='white', label='outrage-fear')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Performance (AUC)')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

def autolabel(rows):
    """Attach a text label above each bar in *rects*, displaying its height."""
    for r in rows:
        height = r.get_height()
        ax.annotate('{}'.format(height),
                    xy=(r.get_x() + r.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(row1)
autolabel(row2)
autolabel(row3)

plt.show()
